# Mistral-7B-Instruct QLoRA for Oracle-SFT
base_model: "{{MISTRAL_MODEL}}"        # replaced by the launcher
output_dir: "{{MISTRAL}}/checkpoints/sft_qlora_v1"

seq_len: 8192
train_file: "{{MISTRAL}}/data/processed/sft/train_fit.jsonl"
dev_file:   "{{MISTRAL}}/data/processed/sft/dev_fit.jsonl"

# QLoRA / PEFT
lora:
  r: 64
  alpha: 128
  dropout: 0.05
  target_modules: [q_proj, k_proj, v_proj, o_proj, up_proj, down_proj, gate_proj]
  bias: "none"
  task_type: "CAUSAL_LM"

# 4-bit quantization
bnb:
  load_in_4bit: true
  quant_type: "nf4"
  use_double_quant: true
  compute_dtype: "bfloat16"

# training
epochs: 6
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 2.0e-4
weight_decay: 0.05
warmup_ratio: 0.05
lr_scheduler_type: "cosine"
max_grad_norm: 1.0
gradient_checkpointing: true
bf16: true
tf32: true
packing: true         # pack sequences up to 8192
eval_strategy: "steps"
eval_steps: 100
save_steps: 100
save_total_limit: 2
logging_steps: 10
