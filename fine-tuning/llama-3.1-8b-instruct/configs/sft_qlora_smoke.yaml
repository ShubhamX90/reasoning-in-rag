# === QLoRA SFT (smoke) ===
model:
  name: meta-llama/Llama-3.1-8B-Instruct
  attn_implementation: eager
  use_gradient_checkpointing: true
  torch_dtype: bfloat16

prompts:
  system_path: prompts/sft/system_sft.txt
  user_path:   prompts/sft/user_sft.txt

data:
  train_path: data/splits/train.jsonl
  dev_path:   data/splits/dev.jsonl
  max_seq_len: 2048         # smaller for smoke
  max_docs: 8               # smaller for smoke
  include_snippets: true

lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: [q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj]
  bias: none
  task_type: CAUSAL_LM
  inference_mode: false
  load_in_4bit: true
  bnb_4bit_compute_dtype: bfloat16
  bnb_4bit_quant_type: nf4
  bnb_4bit_use_double_quant: true

train:
  num_train_epochs: 1
  max_steps: 80            # <-- hard stop early
  learning_rate: 2.0e-4
  weight_decay: 0.0
  max_grad_norm: 1.0
  lr_scheduler_type: cosine
  warmup_steps: 10

batching:
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 8   # effective batch ~= 2*8 = 16 sequences/step (packed)
  packing: true
  dataloader_num_workers: 2

runtime:
  output_dir: checkpoints/sft_qlora_smoke
  logging_steps: 10
  eval_steps: 40
  save_steps: 80
  save_total_limit: 1
  seed: 42
  report_to: none
  bf16: true
  tf32: true
  gradient_checkpointing: true

eval:
  do_sample: false
  max_new_tokens: 256
  num_examples: 4
